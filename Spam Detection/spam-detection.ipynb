{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes algorithm for spam detection\n",
    "\n",
    "Here we predict if a sms message is 'spam' or 'ham' (i.e. not 'spam') using the Bernoulli Naive Bayes *classifier*.\n",
    "\n",
    "The training data is from the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Getting, understanding, and cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the usual libraries\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "df = pd.read_csv('SMSSpamCollection', sep = '\\t', header=None, names=['label', 'sms_message'])\n",
    "\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocesssing\n",
    "Changing our labels as 0 and 1 as it is easier to work with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']=df.label.map({'spam':1, 'ham':0})\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dcoument into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples:  4179\n",
      "The number of test exampels:  (1393,)\n"
     ]
    }
   ],
   "source": [
    "# Using the sklearn's method for seperating the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_msgs, df_test_msgs, df_ytrain, df_ytest = train_test_split(df['sms_message'],df['label'], random_state=0)\n",
    "\n",
    "#Looking at the train/test split\n",
    "print(\"The number of training examples: \", df_train_msgs.shape[0])\n",
    "print(\"The number of test exampels: \", df_test_msgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating the feature vector from the text (feature extraction)\n",
    "\n",
    "Each message will have its own feature vector.  For each message we will create its feature vector; we will have a feature for every word in our vocabulary.  The $j$th feature is set to one ($x_j=1$) if the $j$th word from our vocabulary occurs in the message, and set the $j$ feature to $0$ otherwise ($x_j=0$).\n",
    "\n",
    "We will use the sklearn method CountVectorize to create the feature vectors for every message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# creating an instance of CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary = True, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of the first training example:  0\n",
      "The first training example:  7287\n"
     ]
    }
   ],
   "source": [
    "# Creating the vocabulary for our feature transformation\n",
    "vectorizer.fit(df_train_msgs)\n",
    "\n",
    "# Next we create the feature vectors for both the training data and the test data\n",
    "X_train = vectorizer.transform(df_train_msgs).toarray() # code to turn the training emails into a feature vector\n",
    "X_test = vectorizer.transform(df_test_msgs).toarray() # code to turn the test email into a feature vector\n",
    "\n",
    "# Changing the target vectors data type  \n",
    "y_train= df_ytrain.to_numpy() \n",
    "y_test = df_ytest.to_numpy()\n",
    "\n",
    "# To observe what the data looks like \n",
    "print(\"The label of the first training example: \", y_train[0])\n",
    "print(\"The first training example: \", len(X_train[2].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probablity for spam: 0.13406317300789664\n",
      "probablity for ham: 0.8659368269921034\n",
      "probabality for class spam\n",
      "[0.01262896 0.0357524  0.00017787 ... 0.00017787 0.0019566  0.00017787]\n",
      "probbality fot class ham\n",
      "[2.76456928e-05 2.76456928e-05 3.04102621e-04 ... 3.04102621e-04\n",
      " 2.76456928e-05 3.04102621e-04]\n"
     ]
    }
   ],
   "source": [
    "probablity_spam_1 = len(df[df['label'] == 1]) / df.shape[0]\n",
    "probablity_ham_0 = len(df[df['label'] == 0]) / df.shape[0]\n",
    "\n",
    "print(\"probablity for spam:\" , probablity_spam_1)\n",
    "print(\"probablity for ham:\" , probablity_ham_0)\n",
    "\n",
    "X_train_spam_1 = X_train[y_train == 1]\n",
    "X_train_ham_0 = X_train[y_train == 0]\n",
    "\n",
    "\n",
    "m = 0.1   # we can change the value of m \n",
    "    \n",
    "X_train_probablity_spam_numerator = X_train_spam_1.sum(axis = 0) + m\n",
    "X_train_probablity_ham_numerator = X_train_ham_0.sum(axis = 0) + m\n",
    "\n",
    "X_train_probablity_spam_denominator = (2 * m) + len(X_train_spam_1)\n",
    "X_train_probablity_ham_denominator = (2 * m) + len(X_train_ham_0)\n",
    "\n",
    "X_train_probablity_given_1 = X_train_probablity_spam_numerator / X_train_probablity_spam_denominator\n",
    "X_train_probablity_given_0 = X_train_probablity_ham_numerator / X_train_probablity_ham_denominator\n",
    "\n",
    "print(\"probabality for class spam\")\n",
    "print(X_train_probablity_given_1)\n",
    "print(\"probbality fot class ham\")\n",
    "print(X_train_probablity_given_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we also predict using the ZeroR classification method\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "[0 1 1 0 0]\n",
      "predicted class for first 50 samples\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1]\n",
      "total number of test examples classified incorrectly\n",
      "19\n",
      "total number of test examples classified correctly\n",
      "1374\n",
      "accuracy for bernoulli: 0.9863603732950467\n",
      "percentage_error: 0.013639626704953339\n",
      "accuracy for zero_R: 0.8671931083991385\n"
     ]
    }
   ],
   "source": [
    "probablity_matrix_given_ham = np.where(X_test == 1, X_train_probablity_given_0, 1 - X_train_probablity_given_0)\n",
    "probablity_matrix_given_spam = np.where(X_test == 1, X_train_probablity_given_1, 1 - X_train_probablity_given_1)\n",
    "\n",
    "log_of_probablity_matrix_given_spam = np.log(probablity_matrix_given_spam)\n",
    "log_of_probablity_matrix_given_ham = np.log(probablity_matrix_given_ham)\n",
    "\n",
    "naive_bayes_probablity_spam = np.sum(log_of_probablity_matrix_given_spam, axis = 1) + np.log(probablity_spam_1)\n",
    "naive_bayes_probablity_ham = np.sum(log_of_probablity_matrix_given_ham, axis = 1) + np.log(probablity_ham_0)\n",
    "\n",
    "predicted_class = np.where(naive_bayes_probablity_spam > naive_bayes_probablity_ham , 1, 0)\n",
    "\n",
    "#error-rate for zero-R \n",
    "\n",
    "if(len(X_train_spam_1) > len(X_train_ham_0)):\n",
    "    highest_probablity = 1\n",
    "else :\n",
    "    highest_probablity = 0\n",
    "\n",
    "accuracy_zero_r = len(y_test[y_test == highest_probablity]) / len(y_test)\n",
    "\n",
    "\n",
    "print(predicted_class[:5])   #first five lements\n",
    "print(predicted_class[-5:])\n",
    "print(\"predicted class for first 50 samples\")\n",
    "print(predicted_class[:50])\n",
    "\n",
    "print(\"percentage_error:\" , percentage_error(predicted_class, y_test))\n",
    "print(\"accuracy for zero_R:\" , accuracy_zero_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_error(predicted_class, y_test):\n",
    "    error_matrix = predicted_class - y_test\n",
    "    error_percentage = (len(error_matrix)-(error_matrix==0).sum())/len(error_matrix)\n",
    "    classified_correctly = len(error_matrix)-(error_matrix!=0).sum()\n",
    "    classified_incorrectly = len(error_matrix)-(error_matrix==0).sum()\n",
    "    print(\"total number of test examples classified incorrectly\")\n",
    "    print(classified_incorrectly)\n",
    "    print(\"total number of test examples classified correctly\")\n",
    "    print(classified_correctly)\n",
    "    accuracy_bernoulli = classified_correctly / (classified_incorrectly + classified_correctly)\n",
    "    print(\"accuracy for bernoulli:\" , accuracy_bernoulli)\n",
    "    return error_percentage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
