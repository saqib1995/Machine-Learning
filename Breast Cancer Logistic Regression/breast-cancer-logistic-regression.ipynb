{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression \n",
    "\n",
    "Here we use gradient ascent to find the weights for the logistic regression problem.   \n",
    "\n",
    "We will use the breast cancer data set.  This data set is described here:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin\n",
    "\n",
    "Goal is to detect if the cells are benign or malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Getting, preprocessing, and understanding the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "cancer = load_breast_cancer()\n",
    "y = cancer.target\n",
    "X = cancer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n"
     ]
    }
   ],
   "source": [
    "# Printing the shape of data (X) and target (Y) values \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing\n",
    "#### Splitting the data into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the data since we will be using gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) \n",
    "print(y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trainng data has dimensions:  (426, 31) . The testing data has dimensions:  (143, 31)\n",
      "[[ 1.         -0.90521714 -0.48626207 -0.8394074  -0.80557355 -0.50755718\n",
      "   0.1454228   0.06947634 -0.3316809  -1.15262223  0.53235287 -0.53353928\n",
      "   0.29973957 -0.04171621 -0.47872297  0.56268224  1.23419747  1.27327171\n",
      "   1.06146621 -0.63852784  0.51085423 -0.82316123  0.20978099 -0.52104187\n",
      "  -0.7200228   0.30403659  1.01126215  0.99687826  0.62213189 -0.56249928\n",
      "   0.63731296]\n",
      " [ 1.          1.36443141  1.67427407  1.47763826  1.29027841  1.73014412\n",
      "   1.40702225  1.28537276  2.39787855 -0.62358371  1.36133627  0.3718613\n",
      "   3.07008442  1.39283566  0.52461757  0.20252768  2.04008512 -0.35752741\n",
      "   1.19120405  1.23146207  2.71622789  0.81954799  1.1729439   0.99179884\n",
      "   0.70812111  0.30843319  0.2006107  -0.1238942   1.0526689  -0.92732426\n",
      "   0.45719967]]\n"
     ]
    }
   ],
   "source": [
    "# Appending a column of ones to x_train \n",
    "ones = np.ones(X_train.shape[0]).reshape((X_train.shape[0], 1))\n",
    "X_train = np.hstack((ones, X_train))\n",
    "\n",
    "ones = np.ones(X_test.shape[0]).reshape((X_test.shape[0], 1))\n",
    "X_test = np.hstack((ones, X_test))\n",
    "\n",
    "\n",
    "print(\"The trainng data has dimensions: \", X_train.shape, \". The testing data has dimensions: \",X_test.shape)\n",
    "print(X_train[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 2: Fitting the model\n",
    "## Implementing Logistic Regression Using Gradient Ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " \n",
    "### Sigmoid($z$)\n",
    "The first function we write here is sigmoid($z$)\n",
    "\n",
    "sigmoid($z$) takes as input a column vector of real numbers, $z^T = [z_1, z_2, ..., z_{N'}]$, where $N'$ is the number of  examples\n",
    "\n",
    "It should produce as output a column vector $\\left[\\frac{1}{1+e^{-z_1}},\\frac{1}{1+e^{-z_2}},...,\\frac{1}{1+e^{-z_{N'}}}\\right]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sig = 1. / (1. + np.exp(-z))\n",
    "    return sig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing ${\\bf w}$\n",
    "For testing the next functions, we create a coefficient vector, ${\\bf w}$.\n",
    "We will initialize the coeffients to be $0$, i.e. ${\\bf w}^T = [0,0,\\ldots ,0]$ (We could have initialized ${\\bf w}$ to any values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1)\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((X_train.shape[1], 1))\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our hypothesis, $h({\\bf x})$\n",
    "The next  function to write is our hypothesis function. \n",
    "\n",
    "For example if our design matrix $X$ consists of single example $X=[1,x_1,x_2,\\ldots,x_d]$ and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, it returns $h({\\bf x})=\\frac{1}{1+e^{-\\left({w_{0}\\cdot 1 +w_1\\cdot x_1+\\cdots w_d\\cdot x_d}\\right)}}$\n",
    "\n",
    "If given a  matrix consisting of $N'$ examples \n",
    "$X=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "and  weights ${\\bf w}^T=[w_0,w_2,\\ldots, w_d]$, the function returns a column vector\n",
    "$[h({\\bf x}^{(1)}),h({\\bf x}^{(2)},\\ldots, h({\\bf x}^{(N')}]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(X, w):\n",
    "    yp = np.dot(X, w);\n",
    "    return yp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X , w):\n",
    "    yp = get_prediction(X, w)\n",
    "    hx = sigmoid(yp)    \n",
    "    return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 1)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "yhat = hypothesis(X_train, w)\n",
    "\n",
    "print(yhat.shape) \n",
    "print(y_train.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Likelihood Function.\n",
    "log likelihood function $\\ell({\\bf w})=\n",
    "\\sum_{i=1}^{N'}y^{(i)}\\ln(h({\\bf x}^{(i)})) +(1- y^{(i)})\\ln(1-h({\\bf x}^{(i)}))$\n",
    "\n",
    "The input is a matrix consisting of $N'$ examples $X=\\left[\\begin{matrix}\n",
    "1& x^{(1)}_1& x^{(1)}_2 &\\ldots& x^{(1)}_d\\\\\n",
    "1& x^{(2)}_1& x^{(2)}_2 &\\ldots& x^{(2)}_d\\\\\n",
    "\\vdots & \\vdots &\\vdots & & \\vdots \\\\\n",
    "1& x^{(N')}_1& x^{(N')}_2 &\\ldots& x^{(N')}_d\\\\\n",
    "\\end{matrix}\\right]$\n",
    "and a column vector ${\\bf y}^T=[y^{(1)},y^{(2)},\\dots,y^{(N')}]$ of labels for $X$.\n",
    "\n",
    "The output is $\\ell({\\bf w})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(X , y , w ):\n",
    "    hx = hypothesis(X, w)\n",
    "    y = y.reshape(y.shape[0],1)\n",
    "    return np.sum(y * np.log(hx) + ((1-y) * np.log(1-hx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-295.2806989185367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood(X_train,y_train,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regresion_Gradient_Ascent(X, y, learning_rate, num_iters):\n",
    "    # Initializing log_likelihood to be an empty list  \n",
    "    log_likelihood_values = []\n",
    "    \n",
    "    w = np.zeros((X.shape[1], 1))\n",
    "    # Initialize N to the number of training examples\n",
    "    N = X.shape[0] \n",
    "    \n",
    "    y = y.reshape(y.shape[0],1)\n",
    "    num_coeff = len(w)\n",
    "    for j in range(1,num_iters+1):\n",
    "        for i in range(num_coeff):\n",
    "            hx = hypothesis(X, w)\n",
    "            diff = y-hx\n",
    "            x_curr = X[:,i]\n",
    "            x_curr = x_curr.reshape(x_curr.shape[0],1)\n",
    "            w[i][0] = w[i][0] + learning_rate/N * np.sum(diff * x_curr)\n",
    "        if (j % 100) == 0:\n",
    "            log_likelihood_values.append(log_likelihood(X,y,w))\n",
    "    return w, log_likelihood_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.93531846]\n",
      " [ 0.35616461]\n",
      " [-1.04442663]\n",
      " [ 0.3815917 ]\n",
      " [ 0.16721161]\n",
      " [-0.29625461]\n",
      " [ 2.77557699]\n",
      " [-2.13226081]\n",
      " [-2.16986363]\n",
      " [ 0.04850516]\n",
      " [ 0.49482736]\n",
      " [-3.53975374]\n",
      " [ 0.92205855]\n",
      " [-2.16574528]\n",
      " [-2.52420249]\n",
      " [ 0.65586384]\n",
      " [ 0.22023554]\n",
      " [ 1.19403452]\n",
      " [-0.55792483]\n",
      " [-0.3951598 ]\n",
      " [ 1.84940865]\n",
      " [-1.62372509]\n",
      " [-2.02402693]\n",
      " [-1.04441369]\n",
      " [-1.81253054]\n",
      " [-1.63930548]\n",
      " [ 0.6595154 ]\n",
      " [-2.63532284]\n",
      " [-1.37774365]\n",
      " [-1.35231401]\n",
      " [-0.57738127]]\n",
      "[-28.21616805871362, -24.565250399635335, -22.878839926603057, -21.86335863210162, -21.16133395507209, -20.62766396958536, -20.194798244108043, -19.82793981828478, -19.50745255291353, -19.221392573680024, -18.962038443986415, -18.72413794645314, -18.50395960498205, -18.298750690019045, -18.106413229763028, -17.92530276407006, -17.754099048488186, -17.591720407554927, -17.437265375138438, -17.28997185880066, -17.149187840695078, -17.014349852425447, -16.884966806591297, -16.760607599836494, -16.640891427440906, -16.525480087223116, -16.414071771473072, -16.306395992583816, -16.202209387362082, -16.101292213179715, -16.003445396686722, -15.9084880295085, -15.816255229618655, -15.726596304833787, -15.639373168074219, -15.554458963995561, -15.471736874227165, -15.391099074381508, -15.312445820664644, -15.23568464763405, -15.160729661643153, -15.087500916944393, -15.01592386341885, -14.945928856548104, -14.877450721616759, -14.810428365280256, -14.744804428598592, -14.680524976450904, -14.617539218937614, -14.555799260964697]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "num_iters = 5000 # The number of iteratins to run the gradient ascent algorithm\n",
    "\n",
    "w, log_likelihood_values = Logistic_Regresion_Gradient_Ascent(X_train, y_train, learning_rate, num_iters)\n",
    "print(w)\n",
    "print(log_likelihood_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Likelihood v/s Number of Iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU5dn/8c+VlSUQVBSLbG5UXBAhqLggAVzrVtRqq3WtuNT+tJXHilTr2lqt9alb1ce6gRp9rDygooCYUNG4gMomi6zBomyyRSSQ5Pr9cU7GSUgmIWEySeb7fr3mlTn7dc9M5pr7Pve5j7k7IiIiNUlJdAAiItK0KVGIiEhMShQiIhKTEoWIiMSkRCEiIjEpUYiISExKFC2UmR1vZguippeZ2dB67Od2MxsTPu9mZsVmlhpOF5jZr3Zd1DXGcKmZTYv3cRpT9OuaoOPfbWZrzeybRMUQi5ldaGaTEh2HBJQomrmaEoC7v+fuP96Vx3L3InfPcveyXbnfpiBMelvNrGvUvKFmtiyBYcVFWMYbgYPdfe9qlg8ys6+ipuP6g8DMepiZm1laxTx3f8HdT4rXMWXnKFGI/OA74NZEB7Gzor9g66g7sM7dV8cjnqoqaqDSfClRtFBVfxVWWXaQmS01swvC6c5m9i8zWxPO/381bLfDLz+gu5m9b2abzWySmXWMWv9MM5trZhvCX6W9opb1CudtCNc5M2rZHmY23sw2mdnHwP4xyvm2mV1XZd5MMxtmgQfNbLWZbTSzWWZ2aIyX7SHg52Z2QA3H8uhlZvasmd0dPh9kZl+Z2U3h8b42s7PN7DQzW2hm35rZLVV22crMXg5fu0/N7PCofdf4noTNVq+a2Rgz2wRcWk2s2Wb2fLj9cjP7g5mlhLXPyUDnsBnx2RivB2Z2D3A88Ei4/iPh/IPMbHJYrgVm9rMqr8s/zGyCmX0H5JrZT8zss/A9XWFmt0cd5t/h3w3hMQZUbW40s2PM7JPwffzEzI6JWlZgZndV9zk0s1bh67Qu/Kx9YmadYpVZquHuejTjB7AMGFrN/EHAV1XXA/oCRcDp4fwUYAZwG5AB7AcsAU4Ol98OjAmf9wAcSAunC4DFQE+gdTh9b7isJ8Ev9BOBdOAmYFF4jPTw+S3h9GBgM/DjcNs84BWgLXAo8B9gWg3lvxh4P2r6YGADkAmcHJatA2BAL+BHNeynAPgV8Leo8g4FlkWt48ABUdPPAndHvd6l4euYDlwJrAFeBNoBhwBbgf2iXtftwLnh+iOApeHzurwn24Gzw3VbV1Oe54Fx4bF7AAuBK6r7bNThs1MA/Cpqui2wArgMSCP4TK0FDol6XTYCx4bxtQr3eVg43RtYBZxd3ecqnHdpxXsO7A6sB34ZHu/n4fQedfgcXgW8DrQBUoF+QPtE/982t4dqFMnleGA8cIm7vxHO6w/s6e53uvs2d18C/A9wQR33+Yy7L3T37wm+3PuE888H3nT3ye6+HfgrwT/xMcDRQBbBP/M2d38XeIPg13wqcA5wm7t/5+5zgOdiHH8s0MfMuofTFwKvuXsJwZdpO+AgwNx9nrt/XUt5/gycYWaH1LH80bYD94TlzQM6An93983uPheYS/AlWWGGu78arv83gi/Uo6nbe1Lo7v/n7uXhax8RvobnAyPDYy8DHiD4ot0VTidIoM+4e6m7fwr8iyDpVRjn7u+H8W119wJ3nx1OzwJeAk6o4/F+Anzp7qPD470EzAfOiFqnps/hdmAPggRf5u4z3H1T/YuenJQoksvVwAfunh81rztBM8SGigfBL/26Vs+je81sIUgAAJ2B5RUL3L2c4FfoPuGyFeG8CsvDZXsS/GpcUWVZtdx9M/AmP3yJXgC8EC57F3gEeBRYZWZPmln7WIVx9zXhNnfGWq8G6/yHE/0VX96ropZ/zw+vD0SVMXwtviJ4berynkS/PlV1JKiJRL9uFa/vrtAdOKpKfBcC0SfGK8VnZkeZWX7YFLaR4LPYkbqp9FkKVS1PTZ/D0cBEIM/MVprZfWaWXsfjSkiJIrlcDXQzswej5q0Alrp7h6hHO3c/rYHHWknwhQKAmRnQlaAZaSXQ1cyiP3/dwmVrCJpwulZZFstLBLWRAQS1lkgidPeH3L0fQdNPT+C/6hD7/UAuQTNFtC0ETRgVdugxtJOie1ilAF0IXpu6vCexhn1eS/BLunvUvIrXtz6qHmsFMLVKfFnufk2MbV4kqM12dfds4HGC5sDq1q2q0mcpVKfyuPt2d7/D3Q8mqM2eTtBcKTtBiaJlSA9P2lU8auoFsxk4BRhoZveG8z4GNpnZ782stZmlmtmhZta/gTG9AvzEzIaEv+BuBEqAD4CPCM5f3GRm6WY2iKAZIS/8Rf4acLuZtTGzg4FLajnWBIIvkjuBlytqKmbWP/wlmx4ebytQa9ded99A0FRzU5VFnwO/CF+jU6h700lN+llw0j0NuIHg9fmQBr4n4Wv4CnCPmbULm+V+B9T3uo1VBOdJKrwB9DSzX4bvX3r4WveqYXsImgC/dfetZnYk8IuoZWuA8irHiDYhPN4vzCzNzM4nOBf1Rg3rR5hZrpkdFjbHbSJIoC2ue3e8KVG0DBMImjUqHrfXtGL4JXgicKqZ3RV+qZxB0Ka7lODX6FNAdkMCcvcFwEXAw+E+zwDOCNvctwFnAqeGyx4DLnb3+eHm1xE0HXxDcGL0mVqOVUKQXIYS/HKt0J6gbX89QVPFOoJzJXXxd3b8Qrk+LEdFU8v/1XFfNRlHcC6h4kTtsPAX8K54T35DkByXANMIXpen6xnn34FzzWy9mT0UNvedRNDMt5LgffoLQQeCmlwL3GlmmwlO0r9SscDdtwD3AO+HTVlHR2/o7usIagI3EryHNxF0xlhbh9j3Bl4lSBLzgKmECdPMHjezx+uwj6Rn7rpxkYiI1Ew1ChERiUmJQkREYlKiEBGRmBKSKMzsPAuGbSg3s5xqlleMUjoiEfGJiMgPdnYwsV1lDjAMeKKG5Q8Cb9V1Zx07dvQePXrUO5jvvvuOtm3b1nv75krlTi4qd3KpS7lnzJix1t33rG1fCUkU7j4PILgGqzIzO5ugS993dd1fjx49mD59er3jKSgoYNCgQfXevrlSuZOLyp1c6lJuM6tx1INK6yWye6yZFQAj3H16ON0WeIegn/8IoNjdq+33bmbDgeEAnTp16peXl1fvOIqLi8nKyqp9xRZG5U4uKndyqUu5c3NzZ7j7Ds3/VcWtRmFm71D9EAej3H1cDZvdATzo7sXV1TaiufuTwJMAOTk53pBfDPrFkVxU7uSicjdc3BKFu+/0bTeBowiuAL2PYGjocjPb6u6P7NroRESkrhJ1Mrta7n58xfPwxibFShIiIomVqO6xP7Xg7msDgDfNbGIi4hARkdolqtfTWIIbzsRa5/bGiUZERGLRldkiIs1U4YpC/vzenylcURjX4zSpcxQiIrKjwhWFFCwrYFCPQfTZuw+L1y/mjQVvcFvBbZSVl5GZlsmUi6cwoOuAuBxfiUJEpAmITgb9OvdjyfolLFy3kMmLJ/OP6f+gzMswDK/mhoDbyrZRsKxAiUJEpCWoSAgDuw+ka3ZXFq5byFtfvsVDHz9EaXkpFt4htrqEADBk3yFcccQVfF/6PddNuI5tZdvISM1gUI9BcYtZiUJEJA4qEkL/ffqTnZnNgnULmLJkCqNnjabMY9+NdVCPQVzW5zJ67tGTDVs38NOXfxpJCHfl3hWpOfTq2CtSC4lXbQKUKEREGqRwRSH5y/I5qONBtE1vy/y18ylYVsD4heMpD27fHhHddGQYZ/34LK4/+no2lWziglcviCSDewbfU+mLf8rFU6pNCAO6DohrgqigRCEiUgeFKwp5Z8k77LvbvmSmZjJv7TzeK3qPKUum7NBM1CqtVSRJGMaFh13ILcffwpotazhlzCmRhHDTsTdFvuhrSgbQeAmhJkoUIiKhiuaio/Y5iuxW2Xyx5gu+WPMF7694n2lF03ZICB0yO0TmpZDCFX2v4O7Bd7No3SKGjh4aSQjX9r+WXnv2ohe9El47qA8lChFJOhUJ4ch9jqR9ZnvmrpnL5MWTyZubt0NzUVpKGru33r1SQri2/7X85cS/MPObmQx5fkgkIVzW5zL2arsXe7Xdq1kmhJooUYhIi1W4opAXil6ApZDdKps5q+cwafEkXpzz4g4JIdVSKzUX/eKwX/CHgX9g/932Z/rK6ZUSwi8O+wVt0tswoOuAFpUQaqJEISLNXkUN4bjux7Fnmz2ZvWo2by16i+dnPk+Zl/HU0qci66ZYyg4J4bYTbmPVd6s4efTJkWTw6/6/5qCOBwEkTUKoiRKFiDQbFQnhhO4nsN/u+zFr1SzGLxjP49Mf36HLadUeRhccegG3DryVtVvWcvKYygmh5x496blHzyZ9QjmRlChEpEmJvkJ5QNcBlJSWMHfNXP71xb+474P7KC0vrXFbwzin1zmMPH4km7Zu4rQXT6OktITMtEx+c+Rv6LVnLyDx3U2bGyUKEUmIqgkB4M0v3+Scl89hW9k2UiyFbtndKNpYVG1t4ScH/oQbj7mRrdu3MuyVYZEawu8G/I6+P+oLBAnh6fynuTz3ciWEBlCiEJFG937R+0H30dJtpKSk0L9zf5ZvXM7KzSsj65R5MNjdzcfdTO9OvSn3ci4fd3kkIdxy/C21XoMwoOsASrqVKCk0kBKFiMTVe8vf49UvXqVdZjs2l2zms28+46P/fMS2sm0AlJeXs3TDUk7a/yQ6ZHbgiRlPUFpeSkZqBk+f+XSlL/nu2d3VZJQAShQisksUrihkytIpdGnfhe1l2/n060+Zunwq89bOi6yTmZpJ3x/15YyeZzB+QTDERUZqBq/97LXIF/0Fh16gE8pNjBKFiOyUSFfUbsfRLrMd01dO542FbzB+wfhKVy5nZ2azR+s9Ir2PUi2VWwfeyqiBoyrtR7WDpk+JQkR2UPVLvNzLmb92Pi/Nfol7p91LqVfueZSZmlnpyuXfDvgt9514Hx999VGlC9UG7zs4so0SQvOhRCEilXxQ9AFDRg+JnGjuvVdvvvz2SzZv21xpPcP42SE/467cu1j93WpOHH1iJCGc0+scUiwl5oVq0nwkJFGY2XnA7UAv4Eh3nx61rDfwBNAeKAf6u/vWRMQp0tIVrihk4uKJdGzTkeJtxXz0n4+YsmQKW0uDf7ny8nJWfbeKX/b+Jf336U96SjpXvn5lJCFcf9T1HLjHgRy4x4G6NqEFS1SNYg4wjCAhRJhZGjAG+KW7zzSzPYDtCYhPpEWpGPMovSidPdrsQeGKQsbNH8f4hZXPKxyw+wEM6DKA/GX5kRPN/3ve/1b6ot9vt/2UEJJMQhKFu88DMLOqi04CZrn7zHC9dY0cmkiLsrlkM89+/iy/m/Q7SstLK4151Cqt1Q/nFSyFW467hbsG3wXUfKIZlBCSkblXf1/WRjm4WQEwoqLpycxuAPoBewF7Annufl8N2w4HhgN06tSpX15eXr3jKC4uJisrq97bN1cqd8vi7ry39j3y1wS1gZVbV7KkeAnlVB4ldWDHgVze43I2lW7iv2b9F9vLt5Oeks4DvR/gkOxDEhR9/LTU97s2dSl3bm7uDHfPqW1fcatRmNk7wN7VLBrl7uNixHMc0B/YAkwxsxnuPqXqiu7+JPAkQE5Ojg8aNKjesRYUFNCQ7Zsrlbt5qvi1f3z342mX0Y5pRdOYtmIaU5ZMYc2WNZH1cjrn8Ie+f2C31rtxy5RbImMe3XvmvZEaQU7fnBZ/orm5v9/1tSvLHbdE4e5D67HZV8BUd18LYGYTgL7ADolCJNlsK9vGs58/y3UTrmN7eeVTd53bdWbvrL1Zu2Vt5JqFYQcNY+TxIwE4ap+jNOaR1FtT6x47EbjJzNoA24ATgAcTG5JIYuQvzeeF2S/g7izdsJTCrwojvZEg6J567sHnct+J99E9uzsffvVhpWsWBvUYFFlXYx5JQySqe+xPgYcJzkO8aWafu/vJ7r7ezP4GfAI4MMHd30xEjCKNpaIpaUCXAZRTTv7SfMYvHM+sVbMi6/TcoydX97uaTm07cce/72B72XYyUjP47dG/pUeHHkDsm+uINESiej2NBcbWsGwMQRdZkRatpLSEf376T66feH2leyykWAqd23WuNPTFpYdfGmlGOqHHCeqRJI2qqTU9ibRY04qm8dLsl3CcRd8uYlrRNL4v/T6y3DAuPvxiHjr1IeaunhuzGUnJQBqTEoXILhZ9u869svZi8uLJvDz3ZaYunxpZZ98O+3Jl3yvp3K4zd0y9I5IQrup3Fe0z26sZSZoUJQqRXWjioomcmXcm28uCXkkVF7RlZ2ZXakq6su+Vkaakgd0H6kpnadKUKETqIfpahrSUNCYumsjbi9/mo68+qjQkxhk9z+CvJ/2Vtd+tDe7opqYkaYaUKER20psL32TYy8PYVr4tMs8w+u/Tn0v7XMqLs1+M3KFt5HEj6blHT3ru0VNNSdJsKVGIxFC4opD8Zfl0atuJoo1FTFg0gekrI4MdR4bafuS0R+jYpiMAV/a9Uk1J0qIoUYhUY3PJZh76+CH+mP9HyrwMCJLCgK4DGN53OM/NfC5Sa7j+qOsjSQKUEKTlUaIQIag5jJ0/ltKyUuasmUPBsoJKw2SkkMItx/8wuuqlfS5VM5IkDSUKSVruzsxVM3noo4d49vNnIyehu7XvxvVHXc++u+3LiEkjIiegTzvwtMi2qjVIMlGikKTyXtF7/HXBX/nHmn/w0X8+YvnG5ZFuqwCplsrVOVdHuq4esfcRqjlI0lOikBZve9l28pfl8+jHjzJ+4fhg5jdwbNdjue2E2+iU1YnzXjlPXVdFaqBEIS3S1GVTeebzZ1i7ZS0frPiA9VvXk5GaEVmeaqn85MCfcPkRlwOo66pIDEoU0mJsL9vOlKVTePjjh5nw5YTI/FP2P4Vr+l9D+8z2nPbCaZSUlqjmILITlCik2SpcUci7S9+lQ6sOzF49m1e/eJV1368jMzUzsk6qpTKw+0DO/PGZQFBzqO4GPiJSMyUKaXbcnedmPseVr18ZGZ47MzWTYb2Gcf4h59OhVQdOfeFU3cBHZBdRopAmr2JcpR93/DHz185nzKwxzFs7L7I8hRRGHjeSPw76Y2SezjmI7DpKFNKkvbPkHU574bRKF78d1+04bjrmJh7++OFIreGk/U+qtJ3OOYjsOkoU0uSUe3mk11LenLxIkjCMGwfcyP0n3Q/A2QedrVqDSCNQopAm47V5r/HoJ4/yxZov+Kb4m6CX0oGn8faityPjKg3rNSyyvmoNIo1DiUISanvZdt5Y+AZ/ef8vfPSfj4DgntG3n3A7Nx17E63TW0fOUajmIJIYCUkUZnYecDvQCzjS3aeH89OBp4C+YWzPu/ufExGjxE/hikJem/caq79bzaQlk4LaQ0b7yFAahpGRmkHr9NaAag4iiZaoGsUcYBjwRJX55wGZ7n6YmbUBvjCzl9x9WWMHKLteWXkZfyv8GzdPuZlyLweCYTT+54z/IbtVNiePPrnaLq0iklgJSRTuPg/AzHZYBLQ1szSgNbAN2NS40cmutm7LOv752T/5x/R/sGzDssj8imE0Tu95OqAurSJNlbl77WvF6+BmBcCIKk1Po4EhQBvgt+7+ZA3bDgeGA3Tq1KlfXl5eveMoLi4mKyur3ts3V/Eu91tfv8XYlWNZ+t1SSr2Uw7MPJ2e3HMYUjWF7+XbSU9J5oPcDHJJ9SNxiqI7e7+SictcsNzd3hrvn1Lozd4/LA3iHoImp6uOsqHUKgJyo6WOBF4B0YC9gAbBfbcfq16+fN0R+fn6Dtm+u4lHusvIyHzd/nPd5vI9zO87teOodqT7689GRdT4o+sD/9O8/+QdFH+zy49eF3u/konLXDJjudfg+j1vTk7sPrcdmvwDedvftwGozex/IAZbs0uBkl6nokXR0l6OZv3Y+D374IF9++yXZmdmV7vOwYtOKyDY6OS3SvDS17rFFwGAzG0PQ9HQ08N+JDUlqUriikMHPD6aktCSSEHI65/DSOS+xT/t9dHJapIVIVPfYnwIPA3sCb5rZ5+5+MvAo8AxBE5UBz7j7rETEKLEVbSzixkk3srV0a2Te8L7Defz0xyOdFHRyWqRlSFSvp7HA2GrmFxN0kZUmpqKJab/d9mPS4kk8P+t53J1USwUgIzWDS/tcWqknm5qYRFqGptb0JE1Q4YpCBj83mK1lQe0hIzWDa3KuYcQxI/jPpv+o1iDSwilRSEzz1szjqjeuiiQJwxhxzAjuGXwPAN2yuylBiLRwKYkOQJqmRd8u4pdjf8mh/ziURd8uIi0ljVRLpVVaK04/8PREhycijUg1CqnktXmv8ef3/synX39KZlomNw64kZuOvYkv132pJiaRJKVEIQCs/3491024jhfnvAhAWkoar5z3SmR4jY5tOipBiCQpNT0luW1l2/j7h3/ngIcPiCQJCK7Yn71qdgIjE5GmQokiSX1Q9AF3z7ub/f6+HzdMvIEj9j6CZ896ltZprUm1VF0kJyIRanpKQs9+/ixXjL+Cci/HMB448QF+O+C3mBk99+ipcxEiUokSRRLZsHUDt757K49+8mhkyI0US6GkrCRyoZwukhORqtT0lATcndEzR3PQIwfx2PTHGNZrGK3TWpNCipqYRKRWqlG0YIUrCsmbk8fU5VOZuWomR+1zFBMunEDfH/WlcEUhT+c/zeW5l6sGISIxKVG0UFOXTWXo6KGUlpcCcPOxN3PPkHtIsaASOaDrAEq6lShJiEit1PTUAk1fOZ3zXz0/kiRSLZX2me0jSUJEZGfom6MFKSktYdSUURz91NGUeRkZqRnq6ioiDaampxagcEUhY2aP4e1Fb7Nk/RIu7XMpD578IPPWzFNXVxFpMCWKZm5a0TRyn8uNNDP99cS/cuMxNwLq6ioiu4aanpqxb4q/4ZL/u6TSuYhtZdsSHJWItDRKFM3UlCVT6PN4H77a9BXpKek6FyEicaOmp2amrLyMO6bewd3/vptee/ZiysVT2FSySeciRCRulCiakfELxnPD2zewdMNSLutzGQ+f+jBtM9oCKEGISNwkpOnJzO43s/lmNsvMxppZh6hlI81skZktMLOTExFfU/TMZ89wVt5ZLN2wlIyUDK7se2UkSYiIxFPMRGFms8Mv82ofDTjuZOBQd+8NLARGhsc7GLgAOAQ4BXjMzFIbcJwWYdz8cVz1xlWR6TIvo2BZQeICEpGkUlvTU8XNkX8d/h0d/r0Q2FLfg7r7pKjJD4Fzw+dnAXnuXgIsNbNFwJFAYX2P1Zy5Ow9++CAjJo3goI4HsXTDUraXbddJaxFpVObuta9k9r67H1vbvHoFYPY68LK7jzGzR4AP3X1MuOyfwFvu/mo12w0HhgN06tSpX15eXr1jKC4uJisrq97bx0OZl/H3L//O61+/zsCOAxl50EgWFy/m842f0ye7D4dkH9LgYzTFcjcGlTu5qNw1y83NneHuObXtq64ns9ua2XHuPg3AzI4BYjaQm9k7wN7VLBrl7uPCdUYBpcALFZtVs361mczdnwSeBMjJyfFBgwbVoRjVKygooCHb72qTF0/m2gnXsujbRfz+2N/zpyF/iss4TU2t3I1F5U4uKnfD1TVRXAE8bWbZ4fQG4PJYG7j70FjLzewSgqatIf5DteYroGvUal2AlXWMsUWY8OUETn/xdBwnPSWds358lgbzE5GEqtM3kLvPcPfDgd7A4e7ex90/re9BzewU4PfAme4efa5jPHCBmWWa2b7AgcDH9T1Oc7PmuzVcPu7yyN3nyr1cJ61FJOHqVKMIaxJ/BAaG01OBO919Yz2P+wiQCUwOb8H5obtf7e5zzewV4AuCJqlfu3tZPY/RrKzdspaho4eyfut6MlMzKS0v1UlrEWkS6tr09DQwB/hZOP1L4BlgWH0O6u4HxFh2D3BPffbbXK3bso6hzw9lwdoFvPHzN8jKyNKV1iLSZNQ1Uezv7udETd9hZp/HI6Bk8+333zJ09FDmr53P+J+P58T9TwR0pbWINB11PUv6vZkdVzFhZscC38cnpOQxcdFEDn3sUOaunsu4C8Zx0v4nJTokEZEd1LVGcQ3wXHiuwoBvgUviFlUSeGfJO5z6wqk4TkZqBu0z2yc6JBGRatUpUbj758DhZtY+nN4U16hauHIv5/q3r4/0biorD4bkUHOTiDRFdWp6MrNsM/sb8C7wrpk9EHVNheykP733J75Y84XuIyEizUJCej0ls9cXvM5t+bdxUe+LuKbfNUxdPlW9m0SkSVOvp0Y0f+18Lhp7EUf86AiePP1JWqe35phuxyQ6LBGRmNTrqZFs3LqRs/POJjM1k7Hnj6V1eutEhyQiUid1rVFcDTxfpdfTpfEKqqUp93IuGnsRi9cvZsrFU+iW3S3RIYmI1Fldez3NRL2e6qVwRSGj3h1F/rJ8Hjn1EQZ2H5jokEREdkpdx3rKBM4BegBp4fhMuPudcYusBShcUUjuc7mUlJWQaqkcsfcRiQ5JRGSn1fUcxTiCu8+VAt9FPSSGSUsmUVJWEpmeunxqAqMREamfup6j6OLup8Q1khZo6fqlAKRYiq6VEJFmq66J4gMzO8zdZ8c1mhZkwdoFvDj7RU7Z/xQGdh+oayVEpNmKmSjMbDbBrUjTgMvMbAlQQtDzyd29d/xDbH7cnWsnXEvbjLY8e/azdMrqlOiQRETqrbYaxemNEkULkzcnj3eXvstjpz2mJCEizV5tiWK9u28ys90bJZoWYOPWjfxu0u/I6ZzD8H7DEx2OiEiD1ZYoXiSoVcwgaIKyqGUO7BenuJqtW/NvZVXxKt74+RukpqQmOhwRkQaLmSjc/fTw776NE07z9unXn/LoJ49ybf9r6de5X6LDERHZJWo7md031nJ3/3TXhtN8TSuaxs//9XOyM7O5e/DdiQ5HRGSXqa3p6YEYyxwYXJ+Dmtn9wBnANmAxcJm7bzCzE4F7gYxw2X+5+7v1OUZjKlxRyODnBrO9fDsZqRnMWzNPXWFFpMWorekpN07HnQyMdPdSM/sLMBL4PbAWOMPdV5rZocBEYJ84xbDL5C/LZ3v5dkB3qxORlqeud7hrY2Z/MLMnw+qf7twAABRBSURBVOkDzazeXWfdfZK7l4aTHwJdwvmfufvKcP5coFU4zlST1jotGDI8BV2BLSItj7l77SuZvUzQ8+lidz/UzFoDhe7ep8EBmL0OvOzuY6rMPxe42t2H1rDdcGA4QKdOnfrl5eXVO4bi4mKysrLqvf0ts29hzsY5nNv1XPp16Mch2YfUe1+NqaHlbq5U7uSictcsNzd3hrvn1Lozd6/1AUwP/34WNW9mLdu8Q3D71KqPs6LWGQWMJUxYUfMPITh3sX9d4uvXr583RH5+fr23XfztYrfbzW9999YGxZAIDSl3c6ZyJxeVu2YV3+21Peo61tO2sBbhAGa2P8FQHrESULU1gQpmdgnBNRpDwoAr5ncJk8fF7r64jvElzGOfPEZqSipX9bsq0aGIiMRFXRPFH4G3ga5m9gJwLA24w52ZnUJw8voEd98SNb8D8CbBie7367v/xrJl+xb++dk/GdZrGPu0b/Ln3EVE6qWud7ibbGafAkcTXJ19vbuvbcBxHwEygcnhTZA+dPergeuAA4BbzezWcN2T3H11A44VNy/OfpENWzdwXf/rEh2KiEjc1PUOd3e6+20Ev/YxsxQze8HdL6zPQd39gBrm3w00i6vV3J2HP36Y3p16c1y34xIdjohI3NT1DnfdzGwkRG6L+n/Al3GLqhmYVjSNWatmcV3/66i4NayISEtU10RxGXBYmCxeB/Ld/fa4RdUMPPLJI3Ro1YELe9erUiUi0mzETBRm1jcc7+kI4O/A+QQ1iam1jQPVkv1n0394bd5rXHHEFbRJb5PocERE4mpnx3paDxwczq/3WE/N3RMznqCsvIxrcq5JdCgiInGXqLGemq2S0hKemPEEpx14Gvvvvn+iwxERibvahhm/yN3HmNnvqlvu7n+LT1hN173T7mX1d6sZsu+QRIciItIoajuZ3Tb8266aR9INnlK4opA7/30nAKPeHUXhisIERyQiEn+1NT09Ef69o+oyM7shXkE1VZMWT6LcywHYVrZNw4mLSFKoa/fY6lTbHNWSZbfKBiDFNJy4iCSPuo71VJ2ku8rsm+JvSLVU/jDwD5y8/8mqTYhIUmhIoqj9RhYtTP6yfI7qchS3D7o90aGIiDSa2i6422xmm6p5bAY6N1KMTcKmkk3MWDmDwT2S8tIREUlitZ3MbtdYgTR17y1/jzIvI3dfXVoiIsmlISezk0r+snwyUjMY0EXnJUQkuShR1FH+snwGdBlA6/TWiQ5FRKRRKVHUwbfff8tnX39Gbg81O4lI8lGiqIN/L/83juv8hIgkJSWKOshfmk/rtNYctc9RiQ5FRKTRKVHUQf6yfI7tdiyZaZmJDkVEpNEpUdRizXdrmL16ts5PiEjSSkiiMLP7zWy+mc0ys7Fm1qHK8m5mVmxmIxIRX7Spy6cCKFGISNJKVI1iMnCou/cGFgIjqyx/EHir0aOqRv7SfNqmtyWnc06iQxERSYiEJAp3n+TupeHkh0CXimVmdjawBJibiNiqenfZuwzsPpD01PREhyIikhDmntix/czsdeDl8E56bYF3gBOBEUCxu/+1hu2GA8MBOnXq1C8vL6/eMRQXF5OVteN9mNaVrOPcD8/lqv2u4oKuF9R7/01VTeVu6VTu5KJy1yw3N3eGu9faXNKQ0WNjMrN3gL2rWTTK3ceF64wCSoEXwmV3AA+6e7FZ7FHM3f1J4EmAnJwcHzRoUL1jLSgooLrtX5r9EgC/GvKrFtn0VFO5WzqVO7mo3A0Xt0Th7kNjLTezS4DTgSH+Q7XmKOBcM7sP6ACUm9lWd38kXnHGkr8sn+zMbI7Y+4hEHF5EpEmIW6KIxcxOAX4PnODuWyrmu/vxUevcTtD0lJAkAUGiGNh9IKkpqYkKQUQk4RLV6+kRoB0w2cw+N7PHExRHjb7a9BWLvl2kbrEikvQSUqNw9wPqsM7tjRBKjfKX5gMweF/dqEhEkpuuzK5B3tw82qS1oXhbcaJDERFJKCWKahSuKOStL99iS+kWThx9IoUrChMdkohIwihRVGPi4ok4QUesbWXbKFhWkNiAREQSSImiGgfufiAAKaSQkZrBoB6DEhuQiEgCKVFUY/fWuwMwvN9wplw8hQFddZ9sEUleCen11NQVbSwC4A8D/8A+7fdJcDQiIomlGkU1ijYWkZaSxt5Z1Y1AIiKSXJQoqlG0qYgu7bvoimwREZQoqlW0sYhu2d0SHYaISJOgRFENJQoRkR8oUVRRVl7GV5u+ont290SHIiLSJChRVPF18deUlpeqRiEiElKiqKKia6wShYhIQImiCiUKEZHKlCiqqEgUXdt3TXAkIiJNgxJFFUUbi9it1W60y2yX6FBERJoEJYoq1DVWRKQyJYoqlChERCpToqhCiUJEpDIliiibSzazfut6JQoRkSgJSRRmdr+ZzTezWWY21sw6RC3rbWaFZjbXzGabWavGiquix5OuyhYR+UGiahSTgUPdvTewEBgJYGZpwBjganc/BBgEbG+soHQNhYjIjhKSKNx9kruXhpMfAl3C5ycBs9x9ZrjeOncva6y4lChERHZk7p7YAMxeB1529zFmdgPQD9gL2BPIc/f7athuODAcoFOnTv3y8vLqHUNxcTFZWVk8tfQp8lbkMfH4iaRay78XRUW5k43KnVxU7prl5ubOcPecWnfm7nF5AO8Ac6p5nBW1zihgLD8krBHAUqAj0AYoBIbUdqx+/fp5Q+Tn57u7+0WvXeQ9/rtHg/bVnFSUO9mo3MlF5a4ZMN3r8H0et3tmu/vQWMvN7BLg9DARVFRrvgKmuvvacJ0JQF9gSrzijKausSIiO0pUr6dTgN8DZ7r7lqhFE4HeZtYmPLF9AvBFY8WlRCEisqO41Shq8QiQCUw2M4AP3f1qd19vZn8DPgEcmODubzZGQBU3LOrWXolCRCRaQhKFux8QY9kYgi6yjeqb4m90wyIRkWroyuzQ8o3LAXWNFRGpSokiFLkqu4OuyhYRiaZEEdINi0REqqdEEdINi0REqqdEEVLXWBGR6ilRhJQoRESqp0QRUqIQEameEgWwpXSLblgkIlIDJQpgdclqQNdQiIhUR4kCJQoRkViUKIBvtn4DKFGIiFRHiYKgRpGWksaPsn6U6FBERJocJQpg9dbVdGnfhdSUln9XOxGRnaVEAawqWaVmJxGRGihREDQ9KVGIiFQv6RNFWXkZa0rW6IZFIiI1SPpE8U3xN5R5mWoUIiI1SPpEUTG8uBKFiEj1lCiUKEREYkr6RFFxC9Su2bphkYhIdRKSKMzsfjObb2azzGysmXUI56eb2XNmNtvM5pnZyHjHUrSxiKy0LNpnto/3oUREmqVE1SgmA4e6e29gIVCREM4DMt39MKAfcJWZ9YhnIEUbi9grc694HkJEpFlLSKJw90nuXhpOfgh0qVgEtDWzNKA1sA3YFM9YijYWsXerveN5CBGRZs3cPbEBmL0OvOzuY8wsHRgNDAHaAL919ydr2G44MBygU6dO/fLy8up1/DPfP5OBuw1kxMEj6rV9c1ZcXExWVlaiw2h0KndyUblrlpubO8Pdc2rbV9oui6oKM3sHqO6n+ih3HxeuMwooBV4Ilx0JlAGdgd2A98zsHXdfUnUnYQJ5EiAnJ8cHDRq00zFuLtnM5qmbWV26msz9MxnQdcBO76M5KygooD6vW3OncicXlbvh4pYo3H1orOVmdglwOjDEf6jW/AJ42923A6vN7H0gB9ghUewKry98HYDp66cz5PkhTLl4StIlCxGR2iSq19MpwO+BM919S9SiImCwBdoCRwPz4xXH9JXTAXCcbWXbKFhWEK9DiYg0W4nq9fQI0A6YbGafm9nj4fxHgSxgDvAJ8Iy7z4pXEOcdfB6t01qTQgoZqRkM6jEoXocSEWm24tb0FIu7H1DD/GKCLrKNYkDXAUy5eApP5z/N5bmXq9lJRKQaCUkUTcmArgMo6VaiJCEiUoOkH8JDRERiU6IQEZGYlChERCQmJQoREYlJiUJERGJSohARkZgSPijgrmBma4DlDdhFR2DtLgqnOVG5k4vKnVzqUu7u7r5nbTtqEYmiocxsel1GUGxpVO7konInl11ZbjU9iYhITEoUIiISkxJFoNqbIyUBlTu5qNzJZZeVW+coREQkJtUoREQkJiUKERGJKakThZmdYmYLzGyRmd2c6HgaysyeNrPVZjYnat7uZjbZzL4M/+4Wzjczeygs+ywz6xu1zSXh+l+Gt6xt0sysq5nlm9k8M5trZteH81t02c2slZl9bGYzw3LfEc7f18w+CsvwspllhPMzw+lF4fIeUfsaGc5fYGYnJ6ZEO8fMUs3sMzN7I5xu8eU2s2VmNju84dv0cF78P+funpQPIBVYDOwHZAAzgYMTHVcDyzQQ6AvMiZp3H3Bz+Pxm4C/h89OAtwAjuOXsR+H83QnuUb47sFv4fLdEl62Wcv8I6Bs+bwcsBA5u6WUP488Kn6cDH4XleQW4IJz/OHBN+Pxa4PHw+QXAy+Hzg8PPfyawb/h/kZro8tWh/L8DXgTeCKdbfLmBZUDHKvPi/jlP5hrFkcAid1/i7tuAPOCsBMfUIO7+b+DbKrPPAp4Lnz8HnB01/3kPfAh0MLMfAScDk939W3dfD0wGTol/9PXn7l+7+6fh883APGAfWnjZw/iLw8n08OHAYODVcH7Vcle8Hq8CQ8zMwvl57l7i7kuBRQT/H02WmXUBfgI8FU4bSVDuGsT9c57MiWIfYEXU9FfhvJamk7t/DcEXKrBXOL+m8jfr1yVsVjiC4Nd1iy972PzyObCa4B9+MbDB3UvDVaLLEClfuHwjsAfNsNzAfwM3AeXh9B4kR7kdmGRmM8xseDgv7p/zZL4VqlUzL5n6CtdU/mb7uphZFvAv4AZ33xT8aKx+1WrmNcuyu3sZ0MfMOgBjgV7VrRb+bRHlNrPTgdXuPsPMBlXMrmbVFlXu0LHuvtLM9gImm9n8GOvusnInc43iK6Br1HQXYGWCYomnVWF1k/Dv6nB+TeVvlq+LmaUTJIkX3P21cHZSlB3A3TcABQRt0R3MrOJHYHQZIuULl2cTNFU2t3IfC5xpZssImowHE9QwWnq5cfeV4d/VBD8MjqQRPufJnCg+AQ4Me0pkEJzkGp/gmOJhPFDRq+ESYFzU/IvDnhFHAxvDautE4CQz2y3sPXFSOK/JCtub/wnMc/e/RS1q0WU3sz3DmgRm1hoYSnB+Jh84N1ytarkrXo9zgXc9OLs5Hrgg7B20L3Ag8HHjlGLnuftId+/i7j0I/m/fdfcLaeHlNrO2Ztau4jnB53MOjfE5T/RZ/EQ+CHoFLCRo1x2V6Hh2QXleAr4GthP8ariCoC12CvBl+Hf3cF0DHg3LPhvIidrP5QQn9hYBlyW6XHUo93EEVedZwOfh47SWXnagN/BZWO45wG3h/P0IvvAWAf8LZIbzW4XTi8Ll+0Xta1T4eiwATk102XbiNRjED72eWnS5w/LNDB9zK76zGuNzriE8REQkpmRuehIRkTpQohARkZiUKEREJCYlChERiUmJQkREYlKikCbJzNzMHoiaHmFmt++ifT9rZufWvmaDj3OeBSPa5leZ39nMXg2f9zGz03bhMTuY2bXVHUukvpQopKkqAYaZWcdEBxLNzFJ3YvUrgGvdPTd6pruvdPeKRNWH4JqPnYkh1tA7HQhGS63uWCL1okQhTVUpwT1/f1t1QdUagZkVh38HmdlUM3vFzBaa2b1mdqEF92yYbWb7R+1mqJm9F653erh9qpndb2afhOP3XxW133wze5HgwqWq8fw83P8cM/tLOO82ggsBHzez+6us3yNcNwO4EzjfgvsLnB9efft0GMNnZnZWuM2lZva/ZvY6waBwWWY2xcw+DY9dMfLxvcD+4f7urzhWuI9WZvZMuP5nZpYbte/XzOxtC+5PcF/U6/FsGOtsM9vhvZDkkMyDAkrT9ygwq+KLq44OJxgY71uCcfafcvcjLbiZ0W+AG8L1egAnAPsD+WZ2AHAxwTAH/c0sE3jfzCaF6x8JHOrBcNQRZtYZ+AvQD1hP8CV+trvfaWaDgRHuPr26QN19W5hQctz9unB/fyIYYuLycHiOj83snXCTAUBvd/82rFX81IPBDzsCH5rZeIL7ERzq7n3C/fWIOuSvw+MeZmYHhbH2DJf1IRh1twRYYGYPE4xCuo+7Hxruq0Psl15aKtUopMly903A88D/24nNPvHg/hQlBEMXVHzRzyZIDhVecfdyd/+SIKEcRDDmzcUWDNv9EcHQCAeG639cNUmE+gMF7r7GgyGsXyC4gVR9nQTcHMZQQDD8RLdw2WR3r7jfiAF/MrNZwDsEw0R3qmXfxwGjAdx9PrAcqEgUU9x9o7tvBb4AuhO8LvuZ2cNmdgqwqQHlkmZMNQpp6v4b+BR4JmpeKeGPHDMzgjsUViiJel4eNV1O5c971bFrKoZf/o27VxogzYKhrL+rIb4axzKvJwPOcfcFVWI4qkoMFwJ7Av3cfbsFI6m2qsO+axL9upUBae6+3swOJ7jRza+BnxGMESRJRjUKadLCX9CvEJwYrrCMoKkHgrt4pddj1+eZWUp43mI/gkHhJgLXWDBkOWbW04JROmP5CDjBzDqGJ7p/DkzdiTg2E9y+tcJE4DdhAsTMjqhhu2yCezJsD881dK9hf9H+TZBgCJucuhGUu1phk1aKu/8LuJXgNruShJQopDl4AIju/fQ/BF/OHwNVf2nX1QKCL/S3gKvDJpenCJpdPg1PAD9BLbVuD4ZtHkkwxPVM4FN3HxdrmyrygYMrTmYDdxEkvllhDHfVsN0LQI6ZTSf48p8fxrOO4NzKnKon0YHHgFQzmw28DFwaNtHVZB+gIGwGezYspyQhjR4rIiIxqUYhIiIxKVGIiEhMShQiIhKTEoWIiMSkRCEiIjEpUYiISExKFCIiEtP/B9N5LUJ5eazSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = np.array(range(0,num_iters,100))\n",
    "plt.plot(iters,log_likelihood_values,'.-',color='green')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Likelihood')\n",
    "plt.title(\"Likelihood vs Number of Iterations.\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 88, FP: 5, TN: 49, FN: 1\n",
      "precision:  0.946236559139785\n",
      "recall:  0.9887640449438202\n",
      "F1:  0.967032967032967\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "test_prediction = hypothesis(X_test, w)\n",
    "test_prediction[test_prediction > threshold] = 1\n",
    "test_prediction[test_prediction < threshold] = 0\n",
    "y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "TP = np.sum(np.logical_and(test_prediction == 1, y_test == 1))\n",
    "TN = np.sum(np.logical_and(test_prediction == 0, y_test == 0))\n",
    "FP = np.sum(np.logical_and(test_prediction == 1, y_test == 0))\n",
    "FN = np.sum(np.logical_and(test_prediction == 0, y_test == 1))\n",
    "print('TP: %i, FP: %i, TN: %i, FN: %i' % (TP,FP,TN,FN))\n",
    "precision = TP/(TP+FP)\n",
    "print(\"precision: \", precision)\n",
    "recall = TP/(TP+FN)\n",
    "print(\"recall: \", recall)\n",
    "f1 = (2*precision*recall)/(precision+recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Test set as a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction, actual, threshold):\n",
    "    actual = actual.reshape(actual.shape[0],1)\n",
    "    prediction[prediction > threshold] = 1\n",
    "    prediction[prediction < threshold] = 0\n",
    "    return np.sum(prediction == actual)/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_prediction, y_test, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regresion_Gradient_Ascent_With_Validation(X, y, Xt, yt, learning_rate, num_iters, pred_threshold):\n",
    "    \n",
    "    w = np.zeros((X.shape[1], 1))\n",
    "    N = X.shape[0] \n",
    "    y = y.reshape(y.shape[0],1)\n",
    "    num_coeff = len(w)\n",
    "    p_acc = 0\n",
    "    p_w = w\n",
    "    for j in range(1,num_iters+1):\n",
    "        acc = accuracy(hypothesis(Xt, w), yt, pred_threshold)\n",
    "        print(\"accuracy: \", acc)\n",
    "        if acc < p_acc:\n",
    "            print(\"acc stars decreasing at iteration: \", j)\n",
    "            break;\n",
    "        else:\n",
    "            p_acc = acc\n",
    "            p_w = w\n",
    "            for i in range(num_coeff):\n",
    "                hx = hypothesis(X, w)\n",
    "                diff = y-hx\n",
    "                x_curr = X[:,i]\n",
    "                x_curr = x_curr.reshape(x_curr.shape[0],1)\n",
    "                w[i][0] = w[i][0] + learning_rate/N * np.sum(diff * x_curr)\n",
    "    return p_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.0\n",
      "accuracy:  0.9230769230769231\n",
      "accuracy:  0.9230769230769231\n",
      "accuracy:  0.9440559440559441\n",
      "accuracy:  0.951048951048951\n",
      "accuracy:  0.951048951048951\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.958041958041958\n",
      "accuracy:  0.965034965034965\n",
      "accuracy:  0.965034965034965\n",
      "accuracy:  0.965034965034965\n",
      "accuracy:  0.965034965034965\n",
      "accuracy:  0.965034965034965\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.972027972027972\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.9790209790209791\n",
      "accuracy:  0.972027972027972\n",
      "acc stars decreasing at iteration:  82\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "new_i = 10000\n",
    "wt = Logistic_Regresion_Gradient_Ascent_With_Validation(X_train,\\\n",
    "                                                         y_train,\\\n",
    "                                                         X_test,\\\n",
    "                                                         y_test,\\\n",
    "                                                         alpha,\\\n",
    "                                                         new_i,\\\n",
    "                                                         threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with cross validation:  0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(hypothesis(X_train, wt), y_train, threshold)\n",
    "print(\"accuracy with cross validation: \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
